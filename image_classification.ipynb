{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "image_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGk6TN-5fjfk"
      },
      "source": [
        "# Upload Input Data\n",
        "# -----------------\n",
        "# Parameters:\n",
        "\n",
        "# Upload Input Data (True, False)\n",
        "UPLOAD_DATA = False\n",
        "\n",
        "# -----------------\n",
        "\n",
        "if UPLOAD_DATA:\n",
        "    from google.colab import files\n",
        "    files.upload()\n",
        "\n",
        "# -----------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vJ79meGwr4g"
      },
      "source": [
        "# Modules Import\n",
        "# --------------\n",
        "\n",
        "import os\n",
        "import enum\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# --------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B40xghGRdjLG"
      },
      "source": [
        "# Transfer Learning Available Base Models\n",
        "# ---------------------------------------\n",
        "\n",
        "class TL_MODEL(enum.Enum):\n",
        "    NONE = False\n",
        "\n",
        "    VGG16 = 'VGG16'\n",
        "    INCEPTIONV3 = 'InceptionV3'\n",
        "    RESNET50 = 'ResNet50'\n",
        "    MOBILENETV2 = 'MobileNetV2'\n",
        "    NASNETMOBILE = 'NASNetMobile'\n",
        "\n",
        "# ---------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I85Z7Zsnbb3"
      },
      "source": [
        "# Model Architecture Parameters\n",
        "# ------------------------------\n",
        "# Parameters:\n",
        "\n",
        "# Image Height\n",
        "IMG_H = 112\n",
        "\n",
        "# Image Width\n",
        "IMG_W = 112\n",
        "\n",
        "# Resize with Padding (True, False)\n",
        "IMAGE_PADDING = False\n",
        "\n",
        "# Detect Faces (True, False)\n",
        "DETECT_FACES = True\n",
        "\n",
        "# Transfer Learning (Value in TL_MODEL)\n",
        "TRANSFER_LEARNING = TL_MODEL.VGG16.value\n",
        "\n",
        "# Model Architecture (1, 2, 3)\n",
        "N_MODEL = 3\n",
        "\n",
        "# Batch Size\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "# Train Model (True, False)\n",
        "TRAIN_MODEL = True\n",
        "\n",
        "# ------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLxakaOhy2DP"
      },
      "source": [
        "# Define Directories\n",
        "# ------------------\n",
        "# Parameters:\n",
        "\n",
        "# Root Directory\n",
        "ROOT_DIR = '/content/image_classification'\n",
        "\n",
        "# ------------------\n",
        "\n",
        "input_dir = '%s/input' % ROOT_DIR\n",
        "output_dir = '%s/working' % ROOT_DIR\n",
        "\n",
        "train_gt = '%s/train_gt.json' % input_dir\n",
        "training_dir = '%s/training' % input_dir\n",
        "test_dir = '%s/test' % input_dir\n",
        "\n",
        "train_faces_gt = '%s/train_faces_gt.json' % output_dir\n",
        "training_faces_dir = '%s/training_faces' % output_dir\n",
        "training_padding_dir = '%s/training_padding' % output_dir\n",
        "\n",
        "model_path = '%s/model.h5py' % output_dir\n",
        "\n",
        "if not os.path.exists(ROOT_DIR):\n",
        "    !unzip /content/image_classification.zip\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# ------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reRiyMCHdV3W"
      },
      "source": [
        "# Random Seed\n",
        "# -----------\n",
        "# Parameters:\n",
        "\n",
        "# Random Seed\n",
        "SEED = 1000\n",
        "\n",
        "# -----------\n",
        "\n",
        "tf.random.set_seed(SEED) \n",
        "\n",
        "# -----------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYz5VFuRdbib"
      },
      "source": [
        "# Load Dataframe\n",
        "# --------------\n",
        "\n",
        "with open(train_gt) as f:\n",
        "  dic = json.load(f)\n",
        "\n",
        "df3 = pd.DataFrame(dic.items())\n",
        "df3.rename(columns = {0:'filename', 1:'class'}, inplace = True)\n",
        "\n",
        "# --------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDZ1QzEEJpX6"
      },
      "source": [
        "# Auxiliary Functions\n",
        "# -------------------\n",
        "\n",
        "def setup_retina_face():\n",
        "    !pip install retinaface --quiet\n",
        "    from retinaface import RetinaFace\n",
        "\n",
        "    return RetinaFace(quality=\"normal\")\n",
        "\n",
        "def show_stats(i, every):\n",
        "    global start_time\n",
        "\n",
        "    if i == 0:\n",
        "        start_time = datetime.now()\n",
        "    if i != 0 and i % every == 0:\n",
        "        end_time = datetime.now()\n",
        "        print('%s: %s' % (i, end_time - start_time))\n",
        "        start_time = end_time\n",
        "\n",
        "def load_image(file_name, test):\n",
        "    file_path = '%s/%s' % (test_dir if test else training_dir, file_name)\n",
        "\n",
        "    rgb_img = Image.open(file_path).convert('RGB')\n",
        "\n",
        "    return rgb_img\n",
        "\n",
        "def crop_image(pixels, face):\n",
        "    h, w, _ = pixels.shape\n",
        "\n",
        "    x1, x2 = face['x1'], face['x2']\n",
        "    y1, y2 = face['y1'], face['y2']\n",
        "    x1, x2, y1, y2 = max(x1, 0), min(x2, w), max(0, y1), min(y2, h)\n",
        "    \n",
        "    return pixels[y1:y2, x1:x2]\n",
        "\n",
        "def make_square(pixels):\n",
        "    x, y = pixels.size\n",
        "    size = max(IMG_H, x, y)\n",
        "\n",
        "    new_img = Image.new('RGB', (size, size), (0, 0, 0, 0))\n",
        "    new_img.paste(pixels, (int((size - x) / 2), int((size - y) / 2)))\n",
        "\n",
        "    return new_img\n",
        "\n",
        "def save_image(pixels, file_name, i):\n",
        "    new_file_name = file_name.split('.')[0] + '_' + str(i) + '.jpg'\n",
        "    new_file_path = '%s/%s' % (training_faces_dir, new_file_name)\n",
        "\n",
        "    new_img = make_square(pixels) if IMAGE_PADDING else pixels\n",
        "    new_img.save(new_file_path)\n",
        "\n",
        "    return new_file_name\n",
        "\n",
        "# -------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wpXWBfDg7rI"
      },
      "source": [
        "# Image Padding \n",
        "# ------------\n",
        "\n",
        "if IMAGE_PADDING and not DETECT_FACES and not os.path.exists(training_padding_dir):\n",
        "    os.makedirs(training_padding_dir)\n",
        "\n",
        "    for row_index, row in df3.iterrows():\n",
        "        show_stats(row_index, every=100)\n",
        "\n",
        "        file_path = '%s/%s' % (training_dir, row['filename'])\n",
        "        new_file_path = '%s/%s' % (training_padding_dir, row['filename'])\n",
        "\n",
        "        rgb_img = Image.open(file_path).convert('RGB')\n",
        "        rgb_img = make_square(rgb_img)\n",
        "\n",
        "        rgb_img.save(new_file_path)\n",
        "\n",
        "# ------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qkl46oJid790",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "016e8c78-9769-4cbd-e411-83cef202af97"
      },
      "source": [
        "# Detect Faces\n",
        "# ------------\n",
        "# Parameters:\n",
        "\n",
        "# Force Reload Images (True, False)\n",
        "FORCE_RELOAD = False\n",
        "\n",
        "# ------------\n",
        "\n",
        "if DETECT_FACES:\n",
        "    if not os.path.exists(training_faces_dir):\n",
        "        os.makedirs(training_faces_dir)\n",
        "        \n",
        "    detector = setup_retina_face()\n",
        "\n",
        "    if os.path.isfile(train_faces_gt) and not FORCE_RELOAD:\n",
        "        # Load Processed Images Dataframe\n",
        "        df2 = pd.read_json(train_faces_gt)\n",
        "    else:\n",
        "        data = []\n",
        "        for row_index, row in df3.loc[(df3['class'] == 0) | (df3['class'] == 1)].iterrows():\n",
        "            show_stats(row_index, every=100)\n",
        "\n",
        "            # Load Image to Process\n",
        "            rgb_img = load_image(row['filename'], test=False)\n",
        "            pixels = np.asarray(rgb_img)\n",
        "\n",
        "            # Process Image\n",
        "            faces = detector.predict(pixels)\n",
        "\n",
        "            for index, face in enumerate(faces):              \n",
        "                # Crop Processed Image  \n",
        "                pixels_cropped = crop_image(pixels, face)\n",
        "                rgb_img_cropped = Image.fromarray(pixels_cropped)\n",
        "\n",
        "                # Save Processed Image\n",
        "                new_file_name = save_image(rgb_img_cropped, row['filename'], index)\n",
        "                data.append([new_file_name, 'mask' if row['class'] == 1 else 'no_mask'])\n",
        "\n",
        "        # Save Processed Images Dataframe\n",
        "        df2 = pd.DataFrame(data, columns=['filename', 'class'])\n",
        "        df2.to_json(train_faces_gt)\n",
        "else:\n",
        "    # Cast Labels to 'str' for Categorical Class Mode\n",
        "    df3['class'] = df3['class'].astype(str)\n",
        "\n",
        "# ------------"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model[normal quality] init ..\n",
            "model success !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0hplSHCeDzq"
      },
      "source": [
        "# Dataframe Splitting\n",
        "# -------------------\n",
        "# Parameters:\n",
        "\n",
        "# Dataframe Split\n",
        "DF_SPLIT = 0.8\n",
        "\n",
        "# -------------------\n",
        "\n",
        "DATAFRAME = df2 if DETECT_FACES else df3\n",
        "\n",
        "probs = np.random.rand(len(DATAFRAME))\n",
        "training_mask = probs < DF_SPLIT\n",
        "validation_mask = (probs >= DF_SPLIT)\n",
        "\n",
        "DF_TRAIN = DATAFRAME[training_mask]\n",
        "DF_VAL = DATAFRAME[validation_mask]\n",
        "\n",
        "# -------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIU8G-i2eoj2"
      },
      "source": [
        "# Data Augmentation\n",
        "# -----------------\n",
        "# Parameters:\n",
        "\n",
        "# Apply Data Augementation (True, False)\n",
        "APPLY_DATA_AUGMENTATION = True\n",
        "\n",
        "# Data Augmentation Parameters\n",
        "WIDTH_SHIFT_RANGE = 10\n",
        "HEIGHT_SHIFT_RANGE = 10\n",
        "ROTATION_RANGE = 10\n",
        "SHEAR_RANGE = 0.1\n",
        "ZOOM_RANGE = 0.1\n",
        "CHANNEL_SHIFT_RANGE = 0.1\n",
        "HORIZONTAL_FLIP = True\n",
        "VERTICAL_FLIP = False\n",
        "FILL_MODE = 'constant'\n",
        "RESCALE = 1./255\n",
        "\n",
        "# -----------------\n",
        "\n",
        "# Training Data Image Generator\n",
        "if APPLY_DATA_AUGMENTATION:\n",
        "    train_data_gen = ImageDataGenerator(width_shift_range=WIDTH_SHIFT_RANGE,\n",
        "                                        height_shift_range=HEIGHT_SHIFT_RANGE,\n",
        "                                        rotation_range=ROTATION_RANGE,\n",
        "                                        shear_range=SHEAR_RANGE,\n",
        "                                        zoom_range=ZOOM_RANGE,\n",
        "                                        channel_shift_range=CHANNEL_SHIFT_RANGE,\n",
        "                                        horizontal_flip=HORIZONTAL_FLIP,\n",
        "                                        vertical_flip=VERTICAL_FLIP,\n",
        "                                        fill_mode=FILL_MODE,\n",
        "                                        rescale=RESCALE)\n",
        "else:\n",
        "    train_data_gen = ImageDataGenerator(rescale=RESCALE)\n",
        "\n",
        "# Validation Data Image Generator\n",
        "val_data_gen = ImageDataGenerator(rescale=RESCALE)\n",
        "\n",
        "# -----------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjyrOFD8fW0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "074ba540-f53b-4b14-b56f-bf781419e75a"
      },
      "source": [
        "# Data Generator\n",
        "# --------------\n",
        "\n",
        "NUM_CLASSES = 2 if DETECT_FACES else 3\n",
        "\n",
        "IMG_SHAPE = (IMG_H, IMG_W) + (3,)\n",
        "\n",
        "if DETECT_FACES:\n",
        "    DF_DIR = training_faces_dir \n",
        "    CLASS_MODE = 'binary'\n",
        "    CLASSES = ['no_mask',\n",
        "              'mask']\n",
        "else:\n",
        "    DF_DIR = training_padding_dir if IMAGE_PADDING else training_dir\n",
        "    CLASS_MODE = 'categorical'\n",
        "    CLASSES = None\n",
        "\n",
        "# Training Data Generator\n",
        "train_gen = train_data_gen.flow_from_dataframe(DF_TRAIN,\n",
        "                                               DF_DIR,\n",
        "                                               batch_size=BATCH_SIZE,\n",
        "                                               target_size=(IMG_H, IMG_W),\n",
        "                                               class_mode=CLASS_MODE,\n",
        "                                               classes=CLASSES,\n",
        "                                               shuffle=True,\n",
        "                                               seed=SEED)\n",
        "\n",
        "# Validation Data Generator\n",
        "val_gen = val_data_gen.flow_from_dataframe(DF_VAL,\n",
        "                                           DF_DIR,\n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           target_size=(IMG_H, IMG_W),\n",
        "                                           class_mode=CLASS_MODE,\n",
        "                                           classes=CLASSES,\n",
        "                                           shuffle=True,\n",
        "                                           seed=SEED)\n",
        "\n",
        "# --------------"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10718 validated image filenames belonging to 2 classes.\n",
            "Found 2729 validated image filenames belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFfd4rzdgklh"
      },
      "source": [
        "# Dataset Loader\n",
        "# --------------\n",
        "\n",
        "OUTPUT_SHAPE = [None] if NUM_CLASSES == 2 else [None, 3]\n",
        "\n",
        "# Training Dataset\n",
        "train_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\n",
        "                                               output_types=(tf.float32, tf.float32),\n",
        "                                               output_shapes=([None, IMG_H, IMG_W, 3], OUTPUT_SHAPE))\n",
        "\n",
        "# Repeat Training Dataset\n",
        "train_dataset = train_dataset.repeat()\n",
        "\n",
        "# Validation Dataset\n",
        "val_dataset = tf.data.Dataset.from_generator(lambda: val_gen, \n",
        "                                             output_types=(tf.float32, tf.float32),\n",
        "                                             output_shapes=([None, IMG_H, IMG_W, 3], OUTPUT_SHAPE))\n",
        "\n",
        "# Repeat Validation Dataset\n",
        "val_dataset = val_dataset.repeat()\n",
        "\n",
        "# --------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5ASaJcwg8eg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ad897f3-c9c4-491f-c438-ec5dfc49cb57"
      },
      "source": [
        "# Model Architecture Setup\n",
        "# ------------------------ \n",
        "\n",
        "OUTPUT_UNITS = 1 if NUM_CLASSES == 2 else NUM_CLASSES\n",
        "C_ACTIVATION = 'sigmoid' if NUM_CLASSES == 2 else 'softmax'\n",
        "\n",
        "if TRANSFER_LEARNING:\n",
        "    BASE_MODEL = getattr(tf.keras.applications, TRANSFER_LEARNING)(\n",
        "        include_top=False,\n",
        "        weights=\"imagenet\",\n",
        "        input_shape=IMG_SHAPE,\n",
        "        classes=NUM_CLASSES\n",
        "    )\n",
        "\n",
        "    BASE_MODEL.trainable = False\n",
        "\n",
        "    BASE_MODEL.summary()\n",
        "\n",
        "# ------------------------"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 112, 112, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 112, 112, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 112, 112, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 56, 56, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 56, 56, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 56, 56, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 28, 28, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 28, 28, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 28, 28, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 28, 28, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 14, 14, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 7, 7, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 7, 7, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 7, 7, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 0\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xowa_UeFa_RK"
      },
      "source": [
        "# Model Architecture 1\n",
        "# --------------------\n",
        "\n",
        "if N_MODEL == 1:\n",
        "    if TRANSFER_LEARNING:\n",
        "        raise Exception('Not available for Transfer Learning.')\n",
        "    else:\n",
        "        START_F = 8\n",
        "        DEPTH = 5\n",
        "\n",
        "        MODEL = tf.keras.Sequential()\n",
        "\n",
        "        for i in range(DEPTH):\n",
        "            if i == 0:\n",
        "                INPUT_SHAPE = IMG_SHAPE\n",
        "            else:\n",
        "                INPUT_SHAPE = [None]\n",
        "\n",
        "            MODEL.add(tf.keras.layers.Conv2D(filters=START_F, \n",
        "                                             kernel_size=(3, 3),\n",
        "                                             strides=(1, 1),\n",
        "                                             padding='same',\n",
        "                                             input_shape=INPUT_SHAPE))\n",
        "            MODEL.add(tf.keras.layers.ReLU())\n",
        "            MODEL.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "            START_F *= 2\n",
        "            \n",
        "        MODEL.add(tf.keras.layers.Flatten())\n",
        "        MODEL.add(tf.keras.layers.Dense(units=512, activation=tf.keras.layers.LeakyReLU(alpha=0.3)))\n",
        "        MODEL.add(tf.keras.layers.Dense(units=OUTPUT_UNITS, activation=C_ACTIVATION))\n",
        "\n",
        "# --------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KKCRVZ54CPD"
      },
      "source": [
        "# Model Architecture 2\n",
        "# --------------------\n",
        "\n",
        "if N_MODEL == 2:    \n",
        "    if TRANSFER_LEARNING:\n",
        "        MODEL = tf.keras.Sequential()\n",
        "        MODEL.add(BASE_MODEL)\n",
        "\n",
        "        MODEL.add(tf.keras.layers.Flatten())\n",
        "        MODEL.add(tf.keras.layers.Dense(256, activation=tf.keras.layers.ReLU(), input_dim=IMG_SHAPE))\n",
        "        MODEL.add(tf.keras.layers.Dense(units=OUTPUT_UNITS, activation=C_ACTIVATION))\n",
        "    else:\n",
        "        raise Exception('Available only for Transfer Learning.')\n",
        "\n",
        "# --------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6H8UC8hkyYO"
      },
      "source": [
        "# Model Architecture 3\n",
        "# --------------------\n",
        "\n",
        "if N_MODEL == 3:    \n",
        "    if TRANSFER_LEARNING == TL_MODEL.VGG16.value:\n",
        "        MODEL = tf.keras.Sequential()\n",
        "        MODEL.add(BASE_MODEL)\n",
        "\n",
        "        MODEL.add(tf.keras.layers.Flatten())\n",
        "        MODEL.add(tf.keras.layers.Dense(128, activation=tf.keras.layers.ReLU(), input_dim=IMG_SHAPE))\n",
        "        MODEL.add(tf.keras.layers.Dense(units=OUTPUT_UNITS, activation=C_ACTIVATION))\n",
        "\n",
        "        BASE_MODEL.trainable = True\n",
        "\n",
        "        for layer in BASE_MODEL.layers:\n",
        "            if layer.name in ['block5_conv1', 'block4_conv1']:\n",
        "                layer.trainable = True\n",
        "            else:\n",
        "                layer.trainable = False\n",
        "\n",
        "    else:\n",
        "        raise Exception('Available only for VGG16.')\n",
        "\n",
        "# --------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqKNRdtAT2pT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd9e18fd-1c32-4d16-a046-fc0d0e42e106"
      },
      "source": [
        "# Model Summary\n",
        "# -------------\n",
        "\n",
        "MODEL.summary()\n",
        "\n",
        "# -------------"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 3, 3, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               589952    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 15,304,769\n",
            "Trainable params: 4,130,049\n",
            "Non-trainable params: 11,174,720\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGk3OZd4mOmP"
      },
      "source": [
        "# Model Optimization\n",
        "# ------------------\n",
        "# Parameters:\n",
        "\n",
        "# Early Stopping (True, False)\n",
        "EARLY_STOP = True\n",
        "\n",
        "# Learning Rate \n",
        "LR = 1e-5\n",
        "\n",
        "# Validation Metrics\n",
        "METRICS = ['accuracy']\n",
        "\n",
        "# ------------------\n",
        "\n",
        "callbacks = []\n",
        "\n",
        "if EARLY_STOP:\n",
        "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "    callbacks.append(es_callback)\n",
        "\n",
        "# Loss Function\n",
        "if DETECT_FACES:\n",
        "    LOSS = tf.keras.losses.BinaryCrossentropy()\n",
        "else:\n",
        "    LOSS = tf.keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=LR)\n",
        "\n",
        "# Compile Model\n",
        "MODEL.compile(optimizer=optimizer, loss=LOSS, metrics=METRICS)\n",
        "\n",
        "# ------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNt0oxZGmYH8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d79e1a1a-6bee-4afc-946e-127b5efd3b40"
      },
      "source": [
        "# Model Fitting\n",
        "# -------------\n",
        "# Parameters:\n",
        "\n",
        "# Number of Epochs\n",
        "EPOCHS = 20\n",
        "\n",
        "# -------------\n",
        "\n",
        "if TRAIN_MODEL:\n",
        "    history = MODEL.fit(x=train_dataset,\n",
        "                        epochs=EPOCHS,\n",
        "                        steps_per_epoch=len(train_gen),\n",
        "                        validation_data=val_dataset,\n",
        "                        validation_steps=len(val_gen), \n",
        "                        callbacks=callbacks)\n",
        "    MODEL.save(model_path)\n",
        "\n",
        "    final_accuracy = history.history[\"val_accuracy\"][-5:]\n",
        "    print(\"FINAL ACCURACY MEAN-5: \", np.mean(final_accuracy))\n",
        "else:\n",
        "    MODEL = load_model(model_path)\n",
        "\n",
        "# -------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xM8mtYsfj7k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "4d7e8864-14d2-4ff4-f45e-463fd4ea9c2b"
      },
      "source": [
        "# Display Loss and Accuracy\n",
        "# -------------------------\n",
        "\n",
        "def display_training_curves(training, validation, title, subplot):\n",
        "    ax = plt.subplot(subplot)\n",
        "    ax.plot(training)\n",
        "    ax.plot(validation)\n",
        "    ax.set_title(title)\n",
        "    ax.set_ylabel(title)\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.legend(['Training', 'Validation'])\n",
        "\n",
        "\n",
        "if TRAIN_MODEL:\n",
        "    plt.subplots(figsize=(15,5))\n",
        "    plt.tight_layout()\n",
        "\n",
        "    display_training_curves(history.history['accuracy'], history.history['val_accuracy'], 'Accuracy', 121)\n",
        "    display_training_curves(history.history['loss'], history.history['val_loss'], 'Loss', 122)\n",
        "\n",
        "# -------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z92s40Zimc6W"
      },
      "source": [
        "# Prediction Auxiliary Functions\n",
        "# ------------------------------\n",
        "\n",
        "def create_csv(results):\n",
        "    csv_fname = 'results_'\n",
        "    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
        "\n",
        "    with open('%s/%s' % (output_dir, csv_fname), 'w') as f:\n",
        "\n",
        "        f.write('Id,Category\\n')\n",
        "\n",
        "        for key, value in results.items():\n",
        "            f.write(key + ',' + str(value) + '\\n')\n",
        "\n",
        "def plot_pred(i, every):\n",
        "    if i != 0 and i % every == 0:\n",
        "        plt.figure()\n",
        "        plt.imshow(pixels)\n",
        "        plt.xlabel(faces_pred if DETECT_FACES else pred, fontsize=30)\n",
        "        plt.show()\n",
        "\n",
        "def prepare_input(rgb_img):\n",
        "    input = rgb_img.resize((IMG_H, IMG_W), Image.ANTIALIAS)\n",
        "    input = make_square(input) if IMAGE_PADDING else input\n",
        "    input = image.img_to_array(input) / 255.0\n",
        "    input = np.expand_dims(input, axis=0)\n",
        "\n",
        "    return input\n",
        "\n",
        "# ------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3w05cuzmgrw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f901865a-8c70-466b-9fa0-bebd7cf4ea78"
      },
      "source": [
        "# Model Evaluation\n",
        "# ----------------\n",
        "# Parameters:\n",
        "\n",
        "# Plot Predictions (True, False)\n",
        "PLOT_PRED = False\n",
        "\n",
        "# ----------------\n",
        "\n",
        "results = {}\n",
        "image_filenames = next(os.walk(test_dir))[2]\n",
        "\n",
        "for row_index, image_name in enumerate(image_filenames):   \n",
        "    show_stats(row_index, every=10)\n",
        "    if PLOT_PRED:\n",
        "        plot_pred(row_index, every=100)\n",
        "\n",
        "    # Load Image to Process\n",
        "    rgb_img = load_image(image_name, test=True)\n",
        "    pixels = np.asarray(rgb_img)\n",
        "\n",
        "    if DETECT_FACES:\n",
        "        # Preprocess Image\n",
        "        faces = detector.predict(pixels)\n",
        "\n",
        "        faces_pred = []\n",
        "        for index, face in enumerate(faces):              \n",
        "            # Data Preparation\n",
        "            pixels_cropped = crop_image(pixels, face)\n",
        "            face_test = prepare_input(Image.fromarray(pixels_cropped))\n",
        "            \n",
        "            # Predict\n",
        "            face_pred = MODEL.predict(face_test)\n",
        "            face_pred = 1 if face_pred < 0.5 else 0\n",
        "            faces_pred.append(face_pred)\n",
        "\n",
        "        # Detect Faces Prediction\n",
        "        pred = 0 if sum(faces_pred) == 0 else 1 if sum(faces_pred) == len(faces_pred) else 2\n",
        "\n",
        "    else:\n",
        "        # Data Preparation\n",
        "        image_test = prepare_input(rgb_img)\n",
        "\n",
        "        # Predict\n",
        "        softmax = MODEL.predict(image_test)\n",
        "        pred = np.argmax(softmax)\n",
        "\n",
        "    results[image_name] = pred\n",
        "\n",
        "create_csv(results)\n",
        "\n",
        "# ----------------"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10: 0:00:02.039226\n",
            "20: 0:00:01.606500\n",
            "30: 0:00:01.580741\n",
            "40: 0:00:01.145802\n",
            "50: 0:00:01.853746\n",
            "60: 0:00:01.287661\n",
            "70: 0:00:01.305056\n",
            "80: 0:00:01.070991\n",
            "90: 0:00:01.392701\n",
            "100: 0:00:01.336218\n",
            "110: 0:00:01.288969\n",
            "120: 0:00:00.960623\n",
            "130: 0:00:01.148699\n",
            "140: 0:00:01.410064\n",
            "150: 0:00:01.047291\n",
            "160: 0:00:01.560203\n",
            "170: 0:00:01.066677\n",
            "180: 0:00:01.059004\n",
            "190: 0:00:01.085553\n",
            "200: 0:00:01.326116\n",
            "210: 0:00:01.033919\n",
            "220: 0:00:01.181927\n",
            "230: 0:00:01.209611\n",
            "240: 0:00:01.601470\n",
            "250: 0:00:01.113798\n",
            "260: 0:00:00.983673\n",
            "270: 0:00:01.185161\n",
            "280: 0:00:01.063120\n",
            "290: 0:00:01.134141\n",
            "300: 0:00:01.395806\n",
            "310: 0:00:01.176852\n",
            "320: 0:00:01.253299\n",
            "330: 0:00:01.098067\n",
            "340: 0:00:01.085720\n",
            "350: 0:00:01.391575\n",
            "360: 0:00:01.118974\n",
            "370: 0:00:01.068747\n",
            "380: 0:00:01.308099\n",
            "390: 0:00:01.269455\n",
            "400: 0:00:01.020947\n",
            "410: 0:00:00.991910\n",
            "420: 0:00:01.126772\n",
            "430: 0:00:01.162631\n",
            "440: 0:00:01.051880\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
