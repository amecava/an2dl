{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload Input Data\n",
    "# -----------------\n",
    "# Parameters:\n",
    "\n",
    "# Upload Input Data (True, False)\n",
    "UPLOAD_DATA = False\n",
    "\n",
    "# -----------------\n",
    "\n",
    "if UPLOAD_DATA:\n",
    "    from google.colab import files\n",
    "    files.upload()\n",
    "\n",
    "# -----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Shell\n",
    "# -----------------\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# -----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules Import\n",
    "# --------------\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import enum\n",
    "import shutil\n",
    "import pathlib\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input \n",
    "\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# --------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer Learning Available Base Models\n",
    "# ---------------------------------------\n",
    "\n",
    "class DATASET_NAME(enum.Enum):\n",
    "    ALL = \"All\"\n",
    "    BIPBIP = \"Bipbip\"\n",
    "    PEAD = \"Pead\"\n",
    "    ROSEAU = \"Roseau\"\n",
    "    WEEDELEC = \"Weedelec\"\n",
    "\n",
    "class PLANT_NAME(enum.Enum):\n",
    "    MAIS = \"Mais\"\n",
    "    HARICOT = \"Haricot\"\n",
    "\n",
    "# ---------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module Parameters\n",
    "# -----------------\n",
    "# Parameters:\n",
    "\n",
    "# Image Height\n",
    "IMG_H = 256\n",
    "\n",
    "# Image Width\n",
    "IMG_W = 256\n",
    "\n",
    "# Number Classes \n",
    "NUM_CLASSES = 3\n",
    "\n",
    "# Batch Size\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "# UNet (True, False) VGG\n",
    "UNET = False\n",
    "\n",
    "# Train Model (True, False)\n",
    "TRAIN_MODEL = True\n",
    "\n",
    "# Training Dataset\n",
    "DATASETS_TRAINING = DATASET_NAME.BIPBIP\n",
    "\n",
    "# -----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Directories\n",
    "# ------------------\n",
    "# Parameters:\n",
    "\n",
    "# Root Directory\n",
    "ROOT_DIR = pathlib.Path(\"/content\")\n",
    "\n",
    "# ------------------\n",
    "\n",
    "development_dataset = ROOT_DIR / \"Development_Dataset\"\n",
    "training_path = development_dataset / \"Training\"\n",
    "\n",
    "bipbip_path = training_path / \"Bipbip\"\n",
    "bipbip_path_haricot = bipbip_path / \"Haricot\"\n",
    "bipbip_path_mais = bipbip_path / \"Mais\"\n",
    "\n",
    "roseau_path = training_path / \"Roseau\"\n",
    "roseau_path_haricot = roseau_path / \"Haricot\"\n",
    "roseau_path_mais = roseau_path / \"Mais\"\n",
    "\n",
    "weedelec_path = training_path / \"Weedelec\"\n",
    "weedelec_path_haricot = weedelec_path / \"Haricot\"\n",
    "weedelec_path_mais = weedelec_path / \"Mais\"\n",
    "\n",
    "pead_path = training_path / \"Pead\"\n",
    "pead_path_haricot = pead_path / \"Haricot\"\n",
    "pead_path_mais = pead_path / \"Mais\"\n",
    "\n",
    "bipbip_path_list = [bipbip_path_haricot, bipbip_path_mais]\n",
    "roseau_path_list = [roseau_path_haricot, roseau_path_mais]\n",
    "pead_path_list = [pead_path_haricot, pead_path_mais]\n",
    "weedelec_path_list = [weedelec_path_haricot, weedelec_path_mais]\n",
    "\n",
    "dictionary = {\n",
    "    DATASET_NAME.ALL: [bipbip_path_haricot, bipbip_path_mais, \n",
    "                       roseau_path_haricot, roseau_path_mais, \n",
    "                       weedelec_path_haricot, weedelec_path_mais],\n",
    "    DATASET_NAME.BIPBIP: [bipbip_path_haricot, bipbip_path_mais],\n",
    "    DATASET_NAME.ROSEAU: [roseau_path_haricot, roseau_path_mais],\n",
    "    DATASET_NAME.PEAD: [pead_path_haricot, pead_path_mais],\n",
    "    DATASET_NAME.WEEDELEC: [weedelec_path_haricot, weedelec_path_mais]     \n",
    "}\n",
    "\n",
    "dataset_path_list = dictionary.get(DATASETS_TRAINING)\n",
    "\n",
    "dataset_tiles_path_list = [dataset_path / \"Tiles\" for dataset_path in dataset_path_list]\n",
    "\n",
    "model_path = development_dataset / \"model.h5py\"\n",
    "\n",
    "if not os.path.exists(development_dataset):\n",
    "    !unzip -q /content/Development_Dataset.zip\n",
    "\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Seed\n",
    "# -----------\n",
    "# Parameters:\n",
    "\n",
    "# Random Seed\n",
    "SEED = 1000\n",
    "\n",
    "# -----------\n",
    "\n",
    "tf.random.set_seed(SEED) \n",
    "\n",
    "# -----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary Functions\n",
    "# -------------------\n",
    "\n",
    "def tiling(path, shape, output):\n",
    "\n",
    "    filenames = next(os.walk(path))[2]\n",
    "\n",
    "    v_split = int(shape[1] / 256)\n",
    "    h_split = int(shape[0] / 256)\n",
    "    \n",
    "    for row_index, image_name in enumerate(tqdm(filenames)):   \n",
    "\n",
    "        image = Image.open(path / image_name).resize(shape)\n",
    "\n",
    "        rgb_tensor = tf.convert_to_tensor(np.array(image))\n",
    "        v_slices = tf.split(rgb_tensor, v_split, axis=0)\n",
    "\n",
    "        for i, v_slice in enumerate(v_slices):\n",
    "            h_slices = tf.split(v_slice, h_split, axis=1)\n",
    "\n",
    "            for j, tile in enumerate(h_slices):\n",
    "                file_name = os.path.splitext(image_name)[0]\n",
    "                file_name = file_name + \"_\" + str(i) + \"_\" + str(j) + \".png\"\n",
    "                \n",
    "                Image.fromarray(tile.numpy()).save(output / file_name)\n",
    "\n",
    "def process_dataset(dataset_path, shape):\n",
    "\n",
    "    images_path = dataset_path / \"Images\" \n",
    "    masks_path = dataset_path / \"Masks\"\n",
    "    tiles_path = dataset_path / \"Tiles\"\n",
    "\n",
    "    tiles_images_path = tiles_path / \"Images\" \n",
    "    tiles_masks_path = tiles_path / \"Masks\"\n",
    "\n",
    "    if not os.path.exists(tiles_path):\n",
    "        os.mkdir(tiles_path)\n",
    "        os.mkdir(tiles_images_path)\n",
    "        os.mkdir(tiles_masks_path)\n",
    "\n",
    "    tiling(images_path, shape, tiles_images_path)\n",
    "    tiling(masks_path, shape, tiles_masks_path)\n",
    "\n",
    "# -------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiling\n",
    "# ------\n",
    "# Parameters:\n",
    "\n",
    "# Force Reload Images (True, False)\n",
    "FORCE_RELOAD = False\n",
    "\n",
    "# Shape Parameters used in resizing for the tiling part\n",
    "BIPBIP_SHAPE = (2048, 1536)\n",
    "ROSEAU_SHAPE = (1024,768)\n",
    "WEEDELEC_SHAPE = (5120, 3328)\n",
    "PEAD_SHAPE=(3072,2304)\n",
    "\n",
    "# Real Shape Parameters\n",
    "BIPBIP_REAL_SHAPE = (2048, 1536)\n",
    "ROSEAU_REAL_SHAPE = (1228, 819)\n",
    "WEEDELEC_REAL_SHAPE = (5184, 3456)\n",
    "PEAD_REAL_SHAPE = (3280, 2464)\n",
    "\n",
    "# ------\n",
    "\n",
    "if FORCE_RELOAD:\n",
    "\n",
    "    for dataset in bipbip_path_list:\n",
    "        process_dataset(dataset, shape=BIPBIP_SHAPE)\n",
    "    for dataset in roseau_path_list:\n",
    "        process_dataset(dataset, shape=ROSEAU_SHAPE)\n",
    "    for dataset in weedelec_path_list:\n",
    "        process_dataset(dataset, shape=WEEDELEC_SHAPE)\n",
    "    for dataset in pead_path_list:\n",
    "        process_dataset(dataset, shape=PEAD_SHAPE)\n",
    "\n",
    "# ------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Splitting Function\n",
    "# -----------------------\n",
    "\n",
    "def split_dataset(tiles_path, percentage):\n",
    "\n",
    "    split_path = tiles_path / \"Splits\"\n",
    "    os.mkdir(split_path, mode = 0o666)\n",
    "    train = open(split_path / \"train.txt\", \"w+\")\n",
    "    val = open(split_path / \"val.txt\",\"w+\")\n",
    "\n",
    "    n_images = len(os.listdir(tiles_path / \"Images\"))\n",
    "    n_train_images = (int) (n_images * percentage)\n",
    "    n_val_images = (int) (n_images - n_train_images)\n",
    "\n",
    "    count = 1\n",
    "    count_train = 1\n",
    "    count_val = 1\n",
    "    \n",
    "    for image in os.listdir(tiles_path / \"Images\"):\n",
    "      if count % ((int) (n_images / n_val_images)) == 0:\n",
    "        if count_val < n_val_images:\n",
    "          val.write(image[: -4] + \"\\n\")\n",
    "          count_val += 1\n",
    "          count += 1\n",
    "        elif count_val == n_val_images:\n",
    "          val.write(image[: -4])\n",
    "          count_val += 1\n",
    "          count += 1\n",
    "      else:\n",
    "        if count_train < n_train_images:\n",
    "          train.write(image[: -4] + \"\\n\")\n",
    "          count_train += 1\n",
    "          count += 1\n",
    "        elif count_train == n_train_images:\n",
    "          train.write(image[: -4])\n",
    "          count_train += 1\n",
    "          count +=1\n",
    "\n",
    "    val.close()\n",
    "    train.close() \n",
    "\n",
    "# ----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Splitting Function\n",
    "# -----------------------\n",
    "\n",
    "def split_dataset(tiles_path, percentage):\n",
    "\n",
    "    split_path = tiles_path / \"Splits\"\n",
    "    # os.mkdir(split_path, mode = 0o666)\n",
    "    os.mkdir(split_path)\n",
    "    train = open(split_path / \"train.txt\", \"w+\")\n",
    "    val = open(split_path / \"val.txt\",\"w+\")\n",
    "\n",
    "    n_images = len(os.listdir(tiles_path / \"Images\"))\n",
    "    n_train_images = (int) (n_images * percentage)\n",
    "    n_val_images = (int) (n_images - n_train_images)\n",
    "\n",
    "    count = 1\n",
    "    count_train = 1\n",
    "    count_val = 1\n",
    "    \n",
    "    for image in os.listdir(tiles_path / \"Images\"):\n",
    "      if count % ((int) (n_images / n_val_images)) == 0:\n",
    "        if count_val < n_val_images:\n",
    "          val.write(image[: -4] + \"\\n\")\n",
    "          count_val += 1\n",
    "          count += 1\n",
    "        elif count_val == n_val_images:\n",
    "          val.write(image[: -4])\n",
    "          count_val += 1\n",
    "          count += 1\n",
    "      else:\n",
    "        if count_train < n_train_images:\n",
    "          train.write(image[: -4] + \"\\n\")\n",
    "          count_train += 1\n",
    "          count += 1\n",
    "        elif count_train == n_train_images:\n",
    "          train.write(image[: -4])\n",
    "          count_train += 1\n",
    "          count +=1\n",
    "\n",
    "    val.close()\n",
    "    train.close() \n",
    "\n",
    "# ----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe Splitting\n",
    "# -------------------\n",
    "# Parameters:\n",
    "\n",
    "# Train Percentage\n",
    "TRAIN_P = 0.8\n",
    "\n",
    "# -------------------\n",
    "\n",
    "for dataset_tiles_path in dataset_tiles_path_list:\n",
    "\n",
    "    splits_path = dataset_tiles_path / \"Splits\"\n",
    "\n",
    "    if os.path.exists(splits_path):\n",
    "        shutil.rmtree(dataset_tiles_path / \"Splits\")\n",
    "\n",
    "    split_dataset(dataset_tiles_path, TRAIN_P)\n",
    "\n",
    "# -------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "# -----------------\n",
    "# Parameters:\n",
    "\n",
    "# Apply Data Augementation (True, False)\n",
    "APPLY_DATA_AUGMENTATION = True\n",
    "\n",
    "# Data Augmentation Parameters\n",
    "ROTATION_RANGE = 10\n",
    "WIDTH_SHIFT_RANGE = 10\n",
    "HEIGHT_SHIFT_RANGE = 10\n",
    "ZOOM_RANGE = 0.3\n",
    "HORIZONTAL_FLIP = True\n",
    "VERTICAL_FLIP = True\n",
    "FILL_MODE = \"reflect\"\n",
    "\n",
    "# -----------------\n",
    "\n",
    "if APPLY_DATA_AUGMENTATION:\n",
    "    img_data_gen = ImageDataGenerator(rotation_range=ROTATION_RANGE,\n",
    "                                      width_shift_range=WIDTH_SHIFT_RANGE,\n",
    "                                      height_shift_range=HEIGHT_SHIFT_RANGE,\n",
    "                                      zoom_range=ZOOM_RANGE,\n",
    "                                      horizontal_flip=HORIZONTAL_FLIP,\n",
    "                                      vertical_flip=VERTICAL_FLIP,\n",
    "                                      fill_mode=FILL_MODE)\n",
    "    mask_data_gen = ImageDataGenerator(rotation_range=ROTATION_RANGE,\n",
    "                                       width_shift_range=WIDTH_SHIFT_RANGE,\n",
    "                                       height_shift_range=HEIGHT_SHIFT_RANGE,\n",
    "                                       zoom_range=ZOOM_RANGE,\n",
    "                                       horizontal_flip=HORIZONTAL_FLIP,\n",
    "                                       vertical_flip=VERTICAL_FLIP,\n",
    "                                       fill_mode=FILL_MODE)\n",
    "\n",
    "# -----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Generator\n",
    "# --------------\n",
    "\n",
    "def read_rgb_mask(mask_arr):\n",
    "\n",
    "    new_mask_arr = np.zeros(mask_arr.shape[:2], dtype=mask_arr.dtype)\n",
    "\n",
    "    new_mask_arr[np.where(np.all(mask_arr == [0, 0, 0], axis=-1))] = 0\n",
    "    new_mask_arr[np.where(np.all(mask_arr == [216, 124, 18], axis=-1))] = 0\n",
    "    new_mask_arr[np.where(np.all(mask_arr == [255, 255, 255], axis=-1))] = 1\n",
    "    new_mask_arr[np.where(np.all(mask_arr == [216, 67, 82], axis=-1))] = 2\n",
    "\n",
    "    return new_mask_arr\n",
    "\n",
    "class CustomDataset(tf.keras.utils.Sequence):\n",
    "\n",
    "\n",
    "  def __init__(self, dataset_dirs, which_subset, img_generator=None, mask_generator=None, \n",
    "               preprocessing_function=None, out_shape=[256, 256]):\n",
    "    \n",
    "    subset_filenames = []\n",
    "    \n",
    "    for dataset_dir in dataset_dirs:\n",
    "      if which_subset == \"training\":\n",
    "        subset_file = os.path.join(dataset_dir, \"Splits\", \"train.txt\")\n",
    "      elif which_subset == \"validation\":\n",
    "        subset_file = os.path.join(dataset_dir, \"Splits\", \"val.txt\")\n",
    "    \n",
    "      with open(subset_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "  \n",
    "      for line in lines:\n",
    "        subset_filenames.append(line.strip()) \n",
    "\n",
    "    self.which_subset = which_subset\n",
    "    self.dataset_dirs = dataset_dirs\n",
    "    self.subset_filenames = subset_filenames\n",
    "    self.img_generator = img_generator\n",
    "    self.mask_generator = mask_generator\n",
    "    self.preprocessing_function = preprocessing_function\n",
    "    self.out_shape = out_shape\n",
    "\n",
    "  def __len__(self):\n",
    "\n",
    "    return len(self.subset_filenames)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "      \n",
    "    curr_filename = self.subset_filenames[index]\n",
    "    if \"Bipbip_haricot\" in curr_filename:\n",
    "      dataset_dir = bipbip_path_haricot\n",
    "    elif \"Bipbip_mais\" in curr_filename:\n",
    "      dataset_dir = bipbip_path_mais\n",
    "    elif \"Roseau_haricot\" in curr_filename:\n",
    "      dataset_dir = roseau_path_haricot\n",
    "    elif \"Roseau_mais\" in curr_filename:\n",
    "      dataset_dir = roseau_path_mais \n",
    "    elif \"Weedelec_haricot\" in curr_filename:\n",
    "      dataset_dir = weedelec_path_haricot\n",
    "    elif \"Weedelec_mais\" in curr_filename:\n",
    "      dataset_dir = weedelec_path_mais\n",
    "    elif \"Pead_haricot\" in curr_filename:\n",
    "      dataset_dir = pead_path_haricot\n",
    "    elif \"Pead_mais\" in curr_filename:\n",
    "      dataset_dir = pead_path_mais\n",
    "    \n",
    "    img = Image.open(os.path.join(dataset_dir, \"Tiles\", \"Images\", curr_filename + \".png\"))\n",
    "\n",
    "    mask = Image.open(os.path.join(dataset_dir, \"Tiles\", \"Masks\", curr_filename + \".png\"))\n",
    "\n",
    "    img = img.resize(self.out_shape)\n",
    "    mask = mask.resize(self.out_shape, resample=Image.NEAREST)\n",
    "    \n",
    "    img_arr = np.array(img)\n",
    "    mask_arr = np.array(mask)\n",
    "    mask_arr = read_rgb_mask(mask_arr)\n",
    "    mask_arr = np.expand_dims(mask_arr, -1)\n",
    "\n",
    "    if self.which_subset == \"training\":\n",
    "      if self.img_generator is not None and self.mask_generator is not None:\n",
    "        img_t = self.img_generator.get_random_transform(img_arr.shape, seed=SEED)\n",
    "        mask_t = self.mask_generator.get_random_transform(mask_arr.shape, seed=SEED)\n",
    "        img_arr = self.img_generator.apply_transform(img_arr, img_t)\n",
    "        \n",
    "        out_mask = np.zeros_like(mask_arr)\n",
    "        for c in np.unique(mask_arr):\n",
    "          if c > 0:\n",
    "            curr_class_arr = np.float32(mask_arr == c)\n",
    "            curr_class_arr = self.mask_generator.apply_transform(curr_class_arr, mask_t)\n",
    "            curr_class_arr = np.uint8(curr_class_arr)\n",
    "            curr_class_arr = curr_class_arr * c \n",
    "            out_mask += curr_class_arr\n",
    "    else:\n",
    "      out_mask = mask_arr\n",
    "    \n",
    "    if self.preprocessing_function is not None:\n",
    "        img_arr = self.preprocessing_function(img_arr)\n",
    "\n",
    "    return img_arr, np.float32(out_mask)\n",
    "\n",
    "# --------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Loader\n",
    "# --------------\n",
    "\n",
    "dataset_train = CustomDataset(dataset_tiles_path_list, \"training\", img_generator=img_data_gen, mask_generator=mask_data_gen, preprocessing_function=preprocess_input)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(lambda: dataset_train,\n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([IMG_H, IMG_W, 3], [IMG_H, IMG_W, 1]))\n",
    "\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "train_dataset = train_dataset.repeat()\n",
    "\n",
    "dataset_valid = CustomDataset(dataset_tiles_path_list, \"validation\", preprocessing_function=preprocess_input)\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_generator(lambda: dataset_valid,\n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([IMG_H, IMG_W, 3], [IMG_H, IMG_W, 1]))\n",
    "\n",
    "valid_dataset = valid_dataset.batch(BATCH_SIZE)\n",
    "valid_dataset = valid_dataset.repeat()\n",
    "\n",
    "# --------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Generator Test\n",
    "# -------------------\n",
    "\n",
    "evenly_spaced_interval = np.linspace(0, 1, 3)\n",
    "colors = [cm.rainbow(x) for x in evenly_spaced_interval]\n",
    "\n",
    "iterator = iter(valid_dataset)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(9, 9))\n",
    "\n",
    "augmented_img, target = next(iterator)\n",
    "augmented_img = augmented_img[0]\n",
    "augmented_img = augmented_img\n",
    "\n",
    "target = np.array(target[0, ..., 0])\n",
    "target_img = np.zeros([target.shape[0], target.shape[1], 3])\n",
    "\n",
    "target_img[np.where(target == 0)] = [0, 0, 0]\n",
    "target_img[np.where(target == 1)] = [255, 255, 255]\n",
    "target_img[np.where(target == 2)] = [216, 67, 82]\n",
    "\n",
    "_ = ax[0].imshow(np.uint8(augmented_img))\n",
    "_ = ax[1].imshow(np.uint8(target_img))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# -------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Architecture Setup\n",
    "# ------------------------ \n",
    "\n",
    "if not UNET:\n",
    "    BASE_MODEL = tf.keras.applications.VGG16(weights=\"imagenet\", include_top=False, input_shape=(IMG_H, IMG_W, 3))\n",
    "\n",
    "    for layer in BASE_MODEL.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    BASE_MODEL.summary()\n",
    "\n",
    "# ------------------------ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG Model Architecture\n",
    "# ----------------------\n",
    "\n",
    "def vgg_model(depth, start_f, num_classes):\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # Encoder\n",
    "    # -------\n",
    "    model.add(BASE_MODEL)\n",
    "            \n",
    "    # Decoder\n",
    "    # -------\n",
    "    for i in range(depth):\n",
    "        model.add(tf.keras.layers.UpSampling2D(2, interpolation=\"bilinear\"))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=start_f,\n",
    "                                         kernel_size=(3, 3),\n",
    "                                         strides=(1, 1),\n",
    "                                         padding=\"same\"))\n",
    "        model.add(tf.keras.layers.ReLU())\n",
    "\n",
    "        start_f = start_f // 2\n",
    "\n",
    "    # Prediction Layer\n",
    "    # ----------------\n",
    "    model.add(tf.keras.layers.Conv2D(filters=num_classes,\n",
    "                                     kernel_size=(1, 1),\n",
    "                                     strides=(1, 1),\n",
    "                                     padding=\"same\",\n",
    "                                     activation=\"softmax\"))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# ----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNet Model Architecture\n",
    "# -----------------------\n",
    "\n",
    "def unet_model(depth, start_f, num_classes, dynamic_input_shape):\n",
    "   \n",
    "    layers_skip_connections = []\n",
    "    \n",
    "    # Encoder\n",
    "    # -------\n",
    "    if dynamic_input_shape:\n",
    "        input_shape = [None, None, 3]\n",
    "    else:\n",
    "        input_shape = [img_h, img_w, 3]\n",
    "        \n",
    "    input_layer = tf.keras.layers.Input(input_shape)\n",
    "    layer = input_layer\n",
    "    for i in range(depth):\n",
    "        layer = tf.keras.layers.Conv2D(filters=start_f, \n",
    "                                       kernel_size=(3, 3),\n",
    "                                       strides=(1, 1),\n",
    "                                       padding=\"same\",\n",
    "                                       input_shape=input_shape)(layer)\n",
    "        layer = tf.keras.layers.ReLU()(layer)\n",
    "        layer = tf.keras.layers.Conv2D(filters=start_f, \n",
    "                                       kernel_size=(3, 3),\n",
    "                                       strides=(1, 1),\n",
    "                                       padding=\"same\",\n",
    "                                       input_shape=input_shape)(layer)\n",
    "        layer = tf.keras.layers.ReLU()(layer)\n",
    "        layers_skip_connections.append(layer)\n",
    "        layer = tf.keras.layers.MaxPool2D(pool_size=(2, 2)) (layer)\n",
    "\n",
    "        start_f *= 2\n",
    "\n",
    "    # Bottleneck\n",
    "    layer = tf.keras.layers.Conv2D(filters=start_f, kernel_size=(3, 3), strides=(1, 1), padding=\"same\")(layer)\n",
    "    layer = tf.keras.layers.ReLU()(layer)\n",
    "    layer = tf.keras.layers.Conv2D(filters=start_f, kernel_size=(3, 3), strides=(1, 1), padding=\"same\")(layer)\n",
    "    layer = tf.keras.layers.ReLU()(layer)\n",
    "\n",
    "    start_f = start_f // 2\n",
    "    \n",
    "    # Decoder\n",
    "    # -------\n",
    "    for i in range(depth):\n",
    "        layer = tf.keras.layers.UpSampling2D(size=(2, 2), interpolation=\"bilinear\")(layer)\n",
    "        layer = tf.keras.layers.Conv2D(filters=start_f, kernel_size=(2, 2), strides=(1, 1), padding=\"same\")(layer)\n",
    "        layer = tf.keras.layers.ReLU()(layer)\n",
    "        \n",
    "        first_layer = layers_skip_connections[depth - i - 1]\n",
    "        layer = tf.keras.layers.Concatenate()([first_layer, layer])\n",
    "        \n",
    "        layer = tf.keras.layers.Conv2D(filters=start_f, kernel_size=(3, 3), strides=(1, 1), padding=\"same\")(layer)\n",
    "        layer = tf.keras.layers.ReLU()(layer)\n",
    "        layer = tf.keras.layers.Conv2D(filters=start_f, kernel_size=(3, 3), strides=(1, 1), padding=\"same\")(layer)\n",
    "        layer = tf.keras.layers.ReLU()(layer)\n",
    "\n",
    "        start_f = start_f // 2\n",
    "\n",
    "    # Prediction Layer\n",
    "    # ----------------\n",
    "    layer = tf.keras.layers.Conv2D(filters=start_f, kernel_size=(3, 3), strides=(1, 1), padding=\"same\")(layer)\n",
    "    layer = tf.keras.layers.ReLU()(layer)\n",
    "    layer = tf.keras.layers.Conv2D(filters=start_f, kernel_size=(3, 3), strides=(1, 1), padding=\"same\")(layer)\n",
    "    layer = tf.keras.layers.ReLU()(layer)\n",
    "    layer = tf.keras.layers.Conv2D(filters=num_classes, kernel_size=(1, 1), strides=(1, 1), padding=\"same\", activation=\"softmax\")(layer)\n",
    "        \n",
    "    model = tf.keras.Model(inputs = input_layer, outputs = layer)\n",
    "\n",
    "    return model\n",
    "\n",
    "# -----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Model\n",
    "# --------------\n",
    "\n",
    "if not UNET:    \n",
    "    MODEL = vgg_model(depth=5, start_f=256, num_classes=NUM_CLASSES)\n",
    "else:\n",
    "    MODEL = unet_model(depth=4, start_f=32, num_classes=NUM_CLASSES)     \n",
    "\n",
    "MODEL.summary()\n",
    "\n",
    "# --------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean IoU\n",
    "# --------\n",
    "\n",
    "def meanIoU(y_true, y_pred):\n",
    "    \n",
    "    y_pred = tf.expand_dims(tf.argmax(y_pred, -1), -1)\n",
    "\n",
    "    per_class_iou = []\n",
    "\n",
    "    for i in range(1, NUM_CLASSES):\n",
    "        class_pred = tf.cast(tf.where(y_pred == i, 1, 0), tf.float32)\n",
    "        class_true = tf.cast(tf.where(y_true == i, 1, 0), tf.float32)\n",
    "        intersection = tf.reduce_sum(class_true * class_pred)\n",
    "        union = tf.reduce_sum(class_true) + tf.reduce_sum(class_pred) - intersection\n",
    "    \n",
    "        iou = (intersection + 1e-7) / (union + 1e-7)\n",
    "        per_class_iou.append(iou)\n",
    "\n",
    "    return tf.reduce_mean(per_class_iou)\n",
    "\n",
    "# --------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted Loss Function\n",
    "# ----------------------\n",
    "\n",
    "def weighted_loss(onehot_labels, logits):\n",
    "\n",
    "    class_weights = [0.026, 0.313, 0.661]\n",
    "    weights = tf.reduce_sum(class_weights * onehot_labels, axis=-1)\n",
    "    unweighted_losses = tf.nn.softmax_cross_entropy_with_logits(labels=[onehot_labels], logits=[logits])\n",
    "\n",
    "    weighted_losses = unweighted_losses * weights\n",
    "    loss = tf.reduce_mean(weighted_losses)\n",
    "\n",
    "    return loss\n",
    "\n",
    "# ----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Optimization\n",
    "# ------------------\n",
    "# Parameters:\n",
    "\n",
    "# Early Stopping (True, False)\n",
    "EARLY_STOP = True\n",
    "\n",
    "# Weighted Loss Function (True, False)\n",
    "WEIGHTED_LOSS = False\n",
    "\n",
    "# Checkpoints\n",
    "CHECKPOINT = True\n",
    "\n",
    "# Learning Rate\n",
    "LR = 1e-5\n",
    "\n",
    "# Validation Metrics\n",
    "METRICS = [\"accuracy\", meanIoU]\n",
    "\n",
    "# ------------------\n",
    "\n",
    "callbacks = []\n",
    "\n",
    "if EARLY_STOP:\n",
    "    es_callback = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3,restore_best_weights=True)\n",
    "    callbacks.append(es_callback)\n",
    "\n",
    "if WEIGHTED_LOSS:\n",
    "    loss = weighted_loss\n",
    "else:\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy() \n",
    "\n",
    "if CHECKPOINT:\n",
    "    model_checkpoint_path = development_dataset / \"checkpoints\" / \"checkpoint-{}.ckpt\".format(DATASETS_TRAINING.value)\n",
    "    es_callback = tf.keras.callbacks.ModelCheckpoint(filepath=model_checkpoint_path, verbose=1, save_freq=\"epoch\", save_best_only=True)\n",
    "    callbacks.append(es_callback)\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LR)\n",
    "\n",
    "# Compile Model\n",
    "MODEL.compile(optimizer=optimizer, loss=loss, metrics=METRICS)\n",
    "\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Fitting\n",
    "# -------------\n",
    "# Parameters:\n",
    "\n",
    "# Number of Epochs\n",
    "EPOCHS = 1\n",
    "\n",
    "# -------------\n",
    "\n",
    "if TRAIN_MODEL:\n",
    "    if CHECKPOINT and os.path.exists(model_checkpoint_path):\n",
    "        MODEL = load_model(model_checkpoint_path, custom_objects={'meanIoU': meanIoU})\n",
    "\n",
    "    MODEL.fit(x=train_dataset,\n",
    "              epochs=EPOCHS,\n",
    "              validation_data=valid_dataset,\n",
    "              validation_steps=len(dataset_valid), \n",
    "              callbacks=callbacks)\n",
    "\n",
    "else:\n",
    "    MODEL = load_model(model_checkpoint_path, custom_objects={'meanIoU': meanIoU})\n",
    "\n",
    "# -------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Save\n",
    "# ----------\n",
    "\n",
    "MODEL.save(model_path)\n",
    "\n",
    "# ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary Functions\n",
    "# -------------------\n",
    "\n",
    "def predict(image, shape):\n",
    "\n",
    "    v_split = int(shape[1] / 256)\n",
    "    h_split = int(shape[0] / 256)\n",
    "\n",
    "    rgb_tensor = tf.convert_to_tensor(np.array(image))\n",
    "    v_slices = tf.split(rgb_tensor, v_split, axis=0)\n",
    "\n",
    "    v_pred = []\n",
    "\n",
    "    for i, v_slice in enumerate(v_slices):\n",
    "        h_slices = tf.split(v_slice, h_split, axis=1)\n",
    "\n",
    "        h_pred = []\n",
    "\n",
    "        for j, tile in enumerate(h_slices):\n",
    "            out_sigmoid = MODEL.predict(x=tf.expand_dims(tile, 0))\n",
    "            out_sigmoid = np.transpose(out_sigmoid, (0, 2, 1, 3))\n",
    "            \n",
    "            h_pred.append(out_sigmoid)\n",
    "\n",
    "        split = tf.concat(h_pred, axis=1)\n",
    "        v_pred.append(split)\n",
    "\n",
    "    predicted_class = tf.concat(v_pred, axis=2)\n",
    "    predicted_class = tf.argmax(predicted_class, -1)\n",
    "    predicted_class = predicted_class[0, ...]\n",
    "    predicted_class = np.transpose(predicted_class)\n",
    "\n",
    "    return predicted_class\n",
    "\n",
    "def process_output(array, shape, real_shape=None):\n",
    "\n",
    "    image = np.zeros([shape[1], shape[0], 3])\n",
    "\n",
    "    image[np.where(array == 0)] = [0, 0, 0]\n",
    "    image[np.where(array == 1)] = [255, 255, 255]\n",
    "    image[np.where(array == 2)] = [216, 67, 82]\n",
    "\n",
    "    image = np.uint8(image)\n",
    "    image = Image.fromarray(image, \"RGB\")\n",
    "\n",
    "    if real_shape is not None:\n",
    "        image = image.resize(real_shape, resample=Image.NEAREST)\n",
    "    \n",
    "    return np.array(image)\n",
    "\n",
    "# -------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Test\n",
    "# ---------------\n",
    "# Parameters:\n",
    "\n",
    "# Dataset\n",
    "DATASET_PATH = development_dataset / \"Test_Dev\" / \"Bipbip\" / \"Mais\" / \"Images\"\n",
    "\n",
    "# Image Path\n",
    "IMAGE_NAME = \"Bipbip_mais_im_10441\"\n",
    "\n",
    "# Image Shape\n",
    "SHAPE = BIPBIP_SHAPE\n",
    "\n",
    "# ---------------\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 20))\n",
    "\n",
    "image = Image.open(DATASET_PATH / (IMAGE_NAME + \".jpg\")).resize(SHAPE)\n",
    "\n",
    "predicted_class = predict(image, SHAPE)\n",
    "prediction_img = process_output(predicted_class, SHAPE)\n",
    "\n",
    "_ = ax[0].imshow(np.uint8(image))\n",
    "_ = ax[1].imshow(np.uint8(prediction_img))\n",
    "\n",
    "fig.canvas.draw()\n",
    "\n",
    "# ---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}